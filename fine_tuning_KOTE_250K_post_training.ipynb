{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ysys143/ml2024/blob/main/fine_tuning_KOTE_250K_post_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1huv88jHQjxT"
      },
      "source": [
        "## 파인튜닝\n",
        "구글 마운트, 허깅페이스 로그인"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3YB1_WrO_If",
        "outputId": "1446ad6e-3f07-4a18-ddf3-0c6f504480b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "drive.mount('/content/drive')\n",
        "HF_TOKEN = userdata.get('HF_TOKEN')\n",
        "login(HF_TOKEN, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "D_3insn7Pn40"
      },
      "outputs": [],
      "source": [
        "!pip install -q pytorch-lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ayn09JKQsOM"
      },
      "source": [
        "### 파인튜닝 시작"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "T84TdTuRU7Xp"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J6BMxrdSpnUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676,
          "referenced_widgets": [
            "eb71b6632c68404eb2d00494f91ba214",
            "79a643ad75264371abd01abf91eae32d",
            "f3bed28a5e62486c808514f33791f9c3",
            "463a1e9a48ad4bcd8a1f74c813ddceb8",
            "b7e262f55f9c48f0b4e641e1e9d71cb2",
            "701eb243d5fe409c9932d9b13258f2bf",
            "516301ca1ba9416eb432c077db3bc0c9",
            "5419af13c9be452591f3496b7e7f171f",
            "392feae974a345568e2260d2b97bd776",
            "4e21a989954a4bea89fe2aa475220a26",
            "a35aaa60ef4d4613bdcfeb57cd1eae46"
          ]
        },
        "outputId": "9a91adac-74f8-4ace-b7f2-416e37fec671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "<ipython-input-26-93ec169f7233>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /content/checkpoints exists and is not empty.\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name                    | Type         | Params | Mode \n",
            "-----------------------------------------------------------------\n",
            "0 | electra                 | ElectraModel | 123 M  | train\n",
            "1 | intermediate_classifier | Linear       | 33.8 K | train\n",
            "2 | final_classifier        | Linear       | 135    | train\n",
            "-----------------------------------------------------------------\n",
            "123 M     Trainable params\n",
            "0         Non-trainable params\n",
            "123 M     Total params\n",
            "495.954   Total estimated model params size (MB)\n",
            "227       Modules in train mode\n",
            "0         Modules in eval mode\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: |          | 0/? [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb71b6632c68404eb2d00494f91ba214"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 0, global step 266: 'train_loss' reached 1.02314 (best 1.02314), saving model to '/content/checkpoints/best-checkpoint-v2.ckpt' as top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 1, global step 532: 'train_loss' reached 0.92156 (best 0.92156), saving model to '/content/checkpoints/best-checkpoint-v2.ckpt' as top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 2, global step 798: 'train_loss' reached 0.85194 (best 0.85194), saving model to '/content/checkpoints/best-checkpoint-v2.ckpt' as top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 3, global step 1064: 'train_loss' was not in top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 4, global step 1330: 'train_loss' was not in top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 5, global step 1596: 'train_loss' was not in top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 6, global step 1862: 'train_loss' was not in top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 7, global step 2128: 'train_loss' reached 0.84141 (best 0.84141), saving model to '/content/checkpoints/best-checkpoint-v2.ckpt' as top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 8, global step 2394: 'train_loss' was not in top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Epoch 9, global step 2660: 'train_loss' reached 0.81930 (best 0.81930), saving model to '/content/checkpoints/best-checkpoint-v2.ckpt' as top 1\n",
            "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=10` reached.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from transformers import ElectraModel, AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_length=512):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        comment = str(self.data.iloc[index]['comment'])\n",
        "        label = self.data.iloc[index]['sentiment']\n",
        "\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            comment,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "class KOTESentimentTagger(pl.LightningModule):\n",
        "    def __init__(self, pretrained_path):\n",
        "        super().__init__()\n",
        "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\", revision='v2021')\n",
        "        self.intermediate_classifier = nn.Linear(self.electra.config.hidden_size, 44)\n",
        "        self.final_classifier = nn.Linear(44, 3)  # New layer for 3-class classification\n",
        "\n",
        "        # Load pretrained weights\n",
        "        pretrained_state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
        "        # Only load weights from the electra model, not the old classifier\n",
        "        self.load_state_dict(pretrained_state_dict, strict=False)\n",
        "\n",
        "        # Unfreeze all layers for fine-tuning\n",
        "        for param in self.parameters():\n",
        "            param.requires_grad = True\n",
        "\n",
        "        self.electra.train()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        self.electra.train()\n",
        "        output = self.electra(input_ids, attention_mask=attention_mask)\n",
        "        output = output.last_hidden_state[:,0,:]  # Shape: (batch_size, 768)\n",
        "        intermediate_output = self.intermediate_classifier(output)  # Shape: (batch_size, 44)\n",
        "        output = self.final_classifier(intermediate_output)  # Shape: (batch_size, 3)\n",
        "        output = torch.sigmoid(output)\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['labels']\n",
        "        outputs = self(input_ids, attention_mask)\n",
        "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.AdamW(self.parameters(), lr=2e-7)\n",
        "\n",
        "def train_model(train_csv, pretrained_path, batch_size=64, max_epochs=10): ## batch_size는 A100 기준 64가 적당(gpu 주의단계)\n",
        "    # Load the data\n",
        "    df = pd.read_csv(train_csv)\n",
        "\n",
        "    # Initialize the model\n",
        "    model = KOTESentimentTagger(pretrained_path)\n",
        "\n",
        "    # Create dataset and dataloader\n",
        "    train_dataset = SentimentDataset(df, model.tokenizer)\n",
        "    train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=11, # L4: 11, T4: 7\n",
        "    pin_memory=True  # Add this for faster data transfer to GPU\n",
        "    )\n",
        "\n",
        "\n",
        "    # Define callback\n",
        "    checkpoint_callback = ModelCheckpoint(\n",
        "        dirpath='checkpoints',\n",
        "        filename='best-checkpoint',\n",
        "        save_top_k=1,\n",
        "        verbose=True,\n",
        "        monitor='train_loss',\n",
        "        mode='min'\n",
        "    )\n",
        "\n",
        "    # Initialize trainer\n",
        "    trainer = pl.Trainer(\n",
        "        max_epochs=max_epochs,\n",
        "        callbacks=[checkpoint_callback],\n",
        "        accelerator=\"gpu\",\n",
        "        devices=1,\n",
        "        precision=\"16-mixed\"\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    trainer.fit(model, train_loader)\n",
        "\n",
        "    # Load the best model\n",
        "    best_model_path = checkpoint_callback.best_model_path\n",
        "    best_model = KOTESentimentTagger.load_from_checkpoint(best_model_path, pretrained_path=pretrained_path)\n",
        "\n",
        "    return best_model\n",
        "\n",
        "def process_csv(input_file, output_file, model):\n",
        "    df = pd.read_csv(input_file)\n",
        "    df['sentiment_label'] = -1  # Initialize with -1\n",
        "\n",
        "    model.eval()\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for index, row in tqdm(df.iterrows(), total=df.shape[0], desc=\"Processing comments\", position=0, leave=True):\n",
        "            comment = row['comment']\n",
        "            if pd.isna(comment) or comment.strip() == '':\n",
        "                continue  # Skip empty or NaN comments\n",
        "\n",
        "            encoding = model.tokenizer.encode_plus(\n",
        "                comment,\n",
        "                add_special_tokens=True,\n",
        "                max_length=512,\n",
        "                padding='max_length',\n",
        "                truncation=True,\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "            input_ids = encoding['input_ids'].to(device)\n",
        "            attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "            output = model(input_ids, attention_mask)\n",
        "            sentiment_label = torch.argmax(output, dim=1).item()\n",
        "\n",
        "            df.at[index, 'sentiment_label'] = sentiment_label\n",
        "\n",
        "    df.to_csv(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")\n",
        "\n",
        "# Usage example\n",
        "if __name__ == \"__main__\":\n",
        "    pretrained_path = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/model/JS/fine_tuned_model_with_kote_250K.bin\"\n",
        "    train_csv = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/final_output/training_data/learning_set_train_17000_oversampled.csv\"\n",
        "\n",
        "    try:\n",
        "        trained_model = train_model(train_csv, pretrained_path)\n",
        "    except KeyboardInterrupt:\n",
        "        print(\"Training interrupted. Exiting...\")\n",
        "        sys.exit(1)  # Use sys.exit to exit gracefully\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vv7hWLrCuaeW"
      },
      "outputs": [],
      "source": [
        "# prompt: save the current model with torch\n",
        "torch.save(trained_model.state_dict(), \"/content/drive/MyDrive/2024-NIPA-google-trendpop/model/JS/fine_tuned_model_with_kote_250K_after_trained.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test 1000 data\n",
        "#trained_path = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/model/kote_fine_tuned_model_12000.bin\"\n",
        "#trained_path = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/model/JS/fine_tuned_model_with_kote_250K.bin\"\n",
        "trained_path = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/model/JS/fine_tuned_model_with_kote_250K_post_trained.bin\"\n",
        "trained_model = KOTESentimentTagger(trained_path)\n",
        "\n",
        "input_file = \"/content/drive/MyDrive/2024-NIPA-google-trendpop/labeling/quota_sample_1000_use_this.csv\"\n",
        "output_file =  \"/content/drive/MyDrive/2024-NIPA-google-trendpop/labeling/quota_sample_1000_test.csv\"\n",
        "process_csv(input_file, output_file, trained_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHwI4Rx3I1r1",
        "outputId": "9d0b3a4d-b08d-45d2-dab1-8b6b3624c151"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-93ec169f7233>:48: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  pretrained_state_dict = torch.load(pretrained_path, map_location=torch.device('cpu'))\n",
            "Processing comments: 100%|██████████| 1000/1000 [00:13<00:00, 74.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/drive/MyDrive/2024-NIPA-google-trendpop/labeling/quota_sample_1000_test.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Pv-CN_hZUDK"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "eb71b6632c68404eb2d00494f91ba214": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79a643ad75264371abd01abf91eae32d",
              "IPY_MODEL_f3bed28a5e62486c808514f33791f9c3",
              "IPY_MODEL_463a1e9a48ad4bcd8a1f74c813ddceb8"
            ],
            "layout": "IPY_MODEL_b7e262f55f9c48f0b4e641e1e9d71cb2"
          }
        },
        "79a643ad75264371abd01abf91eae32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_701eb243d5fe409c9932d9b13258f2bf",
            "placeholder": "​",
            "style": "IPY_MODEL_516301ca1ba9416eb432c077db3bc0c9",
            "value": "Epoch 9: 100%"
          }
        },
        "f3bed28a5e62486c808514f33791f9c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5419af13c9be452591f3496b7e7f171f",
            "max": 266,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_392feae974a345568e2260d2b97bd776",
            "value": 266
          }
        },
        "463a1e9a48ad4bcd8a1f74c813ddceb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e21a989954a4bea89fe2aa475220a26",
            "placeholder": "​",
            "style": "IPY_MODEL_a35aaa60ef4d4613bdcfeb57cd1eae46",
            "value": " 266/266 [01:38&lt;00:00,  2.70it/s, v_num=5]"
          }
        },
        "b7e262f55f9c48f0b4e641e1e9d71cb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "701eb243d5fe409c9932d9b13258f2bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516301ca1ba9416eb432c077db3bc0c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5419af13c9be452591f3496b7e7f171f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "392feae974a345568e2260d2b97bd776": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e21a989954a4bea89fe2aa475220a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a35aaa60ef4d4613bdcfeb57cd1eae46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}